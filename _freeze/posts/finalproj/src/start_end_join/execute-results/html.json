{
  "hash": "b5e369686293a3ef8eb39be3ce0a2bad",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Data Gathering and Wrangling\"\nauthor: \"Harrison DeFord\"\ndate: '2022-05-05'\noutput: html_document\nexecute: \n  eval: false\n---\n\n\n\n\n## Setup\n\nThe purpose of this script is to define functions which convert data collected by the python script running on mapping.capital, which are returned as nested JSON files, to geoJSON which can be used for analysis. This file is set up for a dataset of all scooter locations, collected every 15 minutes, from 0600 Eastern to 1000 Eastern on May 1, 2022. The second function defined in this document creates a long dataframe which is a timeseries of scooter locations over time.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvendors = list(\"link\",\"lime\",\"spin\")\n```\n:::\n\n\n\n\nThis code block defines a method to convert the nested JSON returned by scooter vendors to a non-nested geoJSON which can be read by `sf`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\njson2geoJSON <- function(vendor){\n  files <- list.files(path = paste(\"../data/monday/\", vendor, \"/morning/json/\", sep = \"\"), pattern=\"*.json\", full.names=TRUE, recursive=FALSE) #list files in directory\n    lapply(files, function(x) {\n      current_data <- fromJSON(txt = x) # load file\n      current_tibble <- as_tibble(current_data$data$bikes) #convert to tibble\n      current_tibble$timestamp_utc <- as_datetime(current_data$last_updated, tz = Sys.timezone()) #create timestamp column\n      current_sf <- st_as_sf(current_tibble, coords = c(\"lon\",\"lat\"), crs = 4326) #coerce to sf\n      if (!file.exists(paste(\"../data/monday/\", vendor, \"/morning/geoJSON/\",\n                                       current_data$last_updated, \"_\", vendor, \".geoJSON\"))){\n      st_write(current_sf, dsn = paste(\"../data/monday/\", vendor, \"/morning/geoJSON/\",\n                                       current_data$last_updated, \"_\", vendor, \".geoJSON\", sep = \"\")\n               , append = FALSE) #write as geoJSON\n      }\n})\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfor (v in vendors){\n  json2geoJSON(v)\n} #loop through each of link, lime, spin\n```\n:::\n\n\n\n\nThis section of code defines a function which creates a timeseries for each scooter and adds a vendor column which can be grouped by in following scripts.\n\n::: callout-important\nNote 2024-10-11: I cannot emphasize enough how much you *SHOULD NOT USE GLOBAL ASSIGNMENT* (`<<-`) in a function. This was some of the first R code I'd ever written, and I'm leaving it for posterity. However, there are MUCH better ways to do this.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nload_timeseries <- function(vendor){\n  files <- list.files(path = paste(\"../data/monday/\", vendor, \"/morning/geoJSON/\", sep = \"\"), pattern=\"*.geoJSON\", full.names=TRUE, recursive=FALSE) #load files from geoJSON directory\n  list_df <<- vector(mode = \"list\") #empty list\n  for(fn in files){\n    tmp <- st_read(fn) #read each file in geoJSON dir\n    list_df[[which(fn == files)]] <<- tmp #append to list_df\n  }\n  test_sf <<- bind_rows(list_df) #make long df\n  test_sf$vendor <<- vendor #create vendor column\n  test_sf <<- distinct(test_sf) #script adds multiples, need to debug. hacky solution here\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nload_timeseries(\"link\")\nlink_data <- test_sf\nif (!file.exists(\"../results/link_mon_am.gpkg\")){\n  st_write(link_data, dsn = paste0(\"../results/link_mon_am.gpkg\", sep = \"\"), append = FALSE)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nload_timeseries(\"lime\")\nlime_data <- test_sf\nif (!file.exists(\"../results/lime_mon_am.gpkg\")){\n  st_write(lime_data, dsn = paste0(\"../results/lime_mon_am.gpkg\", sep = \"\"), append = FALSE)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nload_timeseries(\"spin\")\nspin_data <- test_sf\nif (!file.exists(\"../results/spin_mon_am.gpkg\")){\n  st_write(spin_data, dsn = paste0(\"../results/spin_mon_am.gpkg\", sep = \"\"), append = FALSE)\n}\n```\n:::\n",
    "supporting": [
      "start_end_join_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}